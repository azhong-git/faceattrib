{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "# definte relu6\n",
    "from tensorflow.python.keras import backend as K\n",
    "def relu6(x):\n",
    "    return K.relu(x, max_value=6)\n",
    "\n",
    "# model = load_model('models/mobilenet_1.0_224_2018_06_18_16_08_08/face_attrib_mobilenet_1.0_224.10-0.18-0.17.hdf5', \n",
    "#                    custom_objects={'relu6': relu6})\n",
    "# input_shape = (224, 224)\n",
    "# model = load_model('models/mobilenet_1.0_192_2018_06_19_14_57_50/face_attrib_mobilenet_1.0_192.09-0.19-0.18.hdf5', \n",
    "#                    custom_objects={'relu6': relu6})\n",
    "# input_shape = (192, 192)\n",
    "# model = load_model('models/mobilenet_0.75_224_2018_06_20_11_40_04/face_attrib_mobilenet_0.75_224.11-0.19-0.17.hdf5', \n",
    "#                    custom_objects={'relu6': relu6})\n",
    "# input_shape = (224, 224)\n",
    "model = load_model('models/mobilenet_0.5_224_2018_06_20_17_04_49/face_attrib_mobilenet_0.5_224.14-0.19-0.18.hdf5', \n",
    "                   custom_objects={'relu6': relu6})\n",
    "input_shape = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from data import load_attributes\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "data_dir = '/data/celeba'\n",
    "val_images_path = os.path.join(data_dir, 'Img/img_align_celeba_crop_middle_val/')\n",
    "test_images_path = os.path.join(data_dir, 'Img/img_align_celeba_crop_middle_test/')\n",
    "attributes_path = os.path.join('.', 'celeba_header_lines_40.p')\n",
    "multilabel_dict, labels = load_attributes(attributes_path)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image / 255.0\n",
    "    image = image - 0.5\n",
    "    image = image * 2.0\n",
    "    return image\n",
    "\n",
    "def get_data_in_X_Y(images_path, multilabel_dict):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for img_path in os.listdir(images_path):\n",
    "        real_img_path = os.path.join(images_path, img_path)\n",
    "        img = image.load_img(real_img_path, target_size=input_shape)\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_image(x)\n",
    "        if img_path in multilabel_dict:\n",
    "            X.append(x)\n",
    "            Y.append(multilabel_dict[img_path])\n",
    "    X=np.array(X)\n",
    "    Y=np.array(Y)\n",
    "    return X, Y\n",
    "val_X, val_Y_gt = get_data_in_X_Y(val_images_path + 'all', multilabel_dict)\n",
    "test_X, test_Y_gt = get_data_in_X_Y(test_images_path + 'all', multilabel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19867/19867 [==============================] - 24s 1ms/step\n",
      "19962/19962 [==============================] - 22s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "val_Y_predicted = model.predict(val_X, batch_size=64, verbose=1)\n",
    "test_Y_predicted = model.predict(test_X, batch_size=64, verbose=1)\n",
    "val_Y_predicted_rounded = np.round(val_Y_predicted)\n",
    "test_Y_predicted_rounded = np.round(test_Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- validation accuracies -------------------------\n",
      "mean: 0.9183\n",
      "5_o_Clock_Shadow, 0.9421\n",
      "Arched_Eyebrows, 0.8617\n",
      "Attractive, 0.8166\n",
      "Bags_Under_Eyes, 0.8418\n",
      "Bald, 0.9897\n",
      "Bangs, 0.9583\n",
      "Big_Lips, 0.8460\n",
      "Big_Nose, 0.8376\n",
      "Black_Hair, 0.9117\n",
      "Blond_Hair, 0.9571\n",
      "Blurry, 0.9666\n",
      "Brown_Hair, 0.8572\n",
      "Bushy_Eyebrows, 0.9297\n",
      "Chubby, 0.9561\n",
      "Double_Chin, 0.9657\n",
      "Eyeglasses, 0.9960\n",
      "Goatee, 0.9682\n",
      "Gray_Hair, 0.9795\n",
      "Heavy_Makeup, 0.9273\n",
      "High_Cheekbones, 0.8905\n",
      "Male, 0.9871\n",
      "Mouth_Slightly_Open, 0.9411\n",
      "Mustache, 0.9628\n",
      "Narrow_Eyes, 0.9376\n",
      "No_Beard, 0.9619\n",
      "Oval_Face, 0.7520\n",
      "Pale_Skin, 0.9667\n",
      "Pointy_Nose, 0.7769\n",
      "Receding_Hairline, 0.9441\n",
      "Rosy_Cheeks, 0.9517\n",
      "Sideburns, 0.9743\n",
      "Smiling, 0.9336\n",
      "Straight_Hair, 0.8493\n",
      "Wavy_Hair, 0.8440\n",
      "Wearing_Earrings, 0.9167\n",
      "Wearing_Hat, 0.9906\n",
      "Wearing_Lipstick, 0.9259\n",
      "Wearing_Necklace, 0.8810\n",
      "Wearing_Necktie, 0.9539\n",
      "Young, 0.8825\n",
      "-------------------- test accuracies -------------------------\n",
      "mean: 0.9141\n",
      "5_o_Clock_Shadow, 0.9461\n",
      "Arched_Eyebrows, 0.8408\n",
      "Attractive, 0.8305\n",
      "Bags_Under_Eyes, 0.8515\n",
      "Bald, 0.9906\n",
      "Bangs, 0.9598\n",
      "Big_Lips, 0.7189\n",
      "Big_Nose, 0.8435\n",
      "Black_Hair, 0.9012\n",
      "Blond_Hair, 0.9611\n",
      "Blurry, 0.9641\n",
      "Brown_Hair, 0.8883\n",
      "Bushy_Eyebrows, 0.9295\n",
      "Chubby, 0.9589\n",
      "Double_Chin, 0.9645\n",
      "Eyeglasses, 0.9968\n",
      "Goatee, 0.9723\n",
      "Gray_Hair, 0.9838\n",
      "Heavy_Makeup, 0.9165\n",
      "High_Cheekbones, 0.8807\n",
      "Male, 0.9821\n",
      "Mouth_Slightly_Open, 0.9404\n",
      "Mustache, 0.9694\n",
      "Narrow_Eyes, 0.8737\n",
      "No_Beard, 0.9638\n",
      "Oval_Face, 0.7514\n",
      "Pale_Skin, 0.9695\n",
      "Pointy_Nose, 0.7764\n",
      "Receding_Hairline, 0.9365\n",
      "Rosy_Cheeks, 0.9521\n",
      "Sideburns, 0.9784\n",
      "Smiling, 0.9268\n",
      "Straight_Hair, 0.8453\n",
      "Wavy_Hair, 0.8494\n",
      "Wearing_Earrings, 0.9039\n",
      "Wearing_Hat, 0.9910\n",
      "Wearing_Lipstick, 0.9439\n",
      "Wearing_Necklace, 0.8644\n",
      "Wearing_Necktie, 0.9592\n",
      "Young, 0.8850\n"
     ]
    }
   ],
   "source": [
    "def get_accuracies(predicted, gt):\n",
    "    assert predicted.shape == gt.shape \n",
    "    num_cols = len(predicted[0])\n",
    "    num_rows = len(predicted)\n",
    "    accuracies = []\n",
    "    for i in range(num_cols):\n",
    "        accuracies.append(0)\n",
    "    for j in range(num_rows):\n",
    "        for i in range(num_cols):\n",
    "            if predicted[j][i] == gt[j][i]:\n",
    "                accuracies[i] += 1\n",
    "    for i in range(num_cols):\n",
    "        accuracies[i] = accuracies[i] / 1.0 / num_rows\n",
    "    return accuracies\n",
    "\n",
    "val_accuracies = get_accuracies(val_Y_predicted_rounded, val_Y_gt)\n",
    "print('-------------------- validation accuracies -------------------------')\n",
    "print('mean: {:.04f}'.format(np.mean(val_accuracies)))\n",
    "for i in range(len(labels)):\n",
    "    print('{}, {:.04f}'.format(labels[i], val_accuracies[i]))\n",
    "test_accuracies = get_accuracies(test_Y_predicted_rounded, test_Y_gt)\n",
    "print('-------------------- test accuracies -------------------------')\n",
    "print('mean: {:.04f}'.format(np.mean(test_accuracies)))\n",
    "for i in range(len(labels)):\n",
    "    print('{}, {:.04f}'.format(labels[i], test_accuracies[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images_path = os.path.join('/data/lfw/lfw_all_funneled_face_crop_l_0.3_r_0.3_t_0.4_d_0.2/all/')\n",
    "new_attributes_path = os.path.join('.', 'lfw_header_lines_40.p')\n",
    "new_multilabel_dict, new_labels = load_attributes(new_attributes_path)\n",
    "new_X, new_Y_gt = get_data_in_X_Y(new_images_path, new_multilabel_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13143/13143 [==============================] - 22s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "new_Y_predicted = model.predict(new_X, batch_size=64, verbose=1)\n",
    "new_Y_predicted_rounded = np.round(new_Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- test accuracies -------------------------\n",
      "mean: 0.7384\n",
      "5_o_Clock_Shadow, 0.6203\n",
      "Arched_Eyebrows, 0.7698\n",
      "Attractive, 0.6747\n",
      "Bags_Under_Eyes, 0.6659\n",
      "Bald, 0.9085\n",
      "Bangs, 0.8598\n",
      "Big_Lips, 0.6674\n",
      "Big_Nose, 0.5404\n",
      "Black_Hair, 0.8745\n",
      "Blond_Hair, 0.9610\n",
      "Blurry, 0.8304\n",
      "Brown_Hair, 0.6669\n",
      "Bushy_Eyebrows, 0.5291\n",
      "Chubby, 0.6743\n",
      "Double_Chin, 0.6810\n",
      "Eyeglasses, 0.9216\n",
      "Goatee, 0.7778\n",
      "Gray_Hair, 0.8535\n",
      "Heavy_Makeup, 0.9340\n",
      "High_Cheekbones, 0.8401\n",
      "Male, 0.9781\n",
      "Mouth_Slightly_Open, 0.7860\n",
      "Mustache, 0.9101\n",
      "Narrow_Eyes, 0.4376\n",
      "No_Beard, 0.7962\n",
      "Oval_Face, 0.4810\n",
      "Pale_Skin, 0.5002\n",
      "Pointy_Nose, 0.3336\n",
      "Receding_Hairline, 0.5225\n",
      "Rosy_Cheeks, 0.8064\n",
      "Sideburns, 0.7043\n",
      "Smiling, 0.8949\n",
      "Straight_Hair, 0.5862\n",
      "Wavy_Hair, 0.5825\n",
      "Wearing_Earrings, 0.8934\n",
      "Wearing_Hat, 0.8974\n",
      "Wearing_Lipstick, 0.9301\n",
      "Wearing_Necklace, 0.8057\n",
      "Wearing_Necktie, 0.6875\n",
      "Young, 0.7526\n"
     ]
    }
   ],
   "source": [
    "new_accuracies = get_accuracies(new_Y_predicted_rounded, new_Y_gt)\n",
    "print('-------------------- test accuracies -------------------------')\n",
    "print('mean: {:.04f}'.format(np.mean(new_accuracies)))\n",
    "for i in range(len(labels)):\n",
    "    print('{}, {:.04f}'.format(labels[i], new_accuracies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
